# Unet implemntation #
#*Slices are aligned in the template space already* See ReadME

import os
import numpy as np
import json

import nibabel as nib
import pytorch_lightning as pl
from torch.utils.data import DataLoader, Dataset
import torch
import monai
from monai.networks.nets import UNet
from sklearn.model_selection import train_test_split, KFold

from monai.transforms import (
    Compose,
    LoadImaged,
    EnsureChannelFirstd,
    Lambda,
    ScaleIntensityRanged,
    ResizeD,
    RandFlipd,
    RandRotateD,
    MapTransform,
    AsDiscrete,
    RandGaussianNoised,
    EnsureTyped,
)



def get_tissue_ids(labels_file_path):
    """
    Reads the label text file to find which integers correspond to
    Gray Matter (GM) and White Matter (WM).
    """
    gm_ids = []
    wm_ids = []

    print(f"Reading labels from: {labels_file_path}")
    with open(labels_file_path, 'r') as f:
        for line in f:

            parts = line.split()
            if not parts or not parts[0].isdigit():
                continue

            label_id = int(parts[0])
            label_name = parts[1].lower()


            # Gray Matter: Cortex, Thalamus, Caudate, Putamen, Pallidum, Hippocampus, Amygdala, Accumbens
            if any(x in label_name for x in ['cortex', 'thalamus', 'caudate', 'putamen', 'pallidum', 'hippocampus', 'amygdala', 'accumbens']):
                gm_ids.append(label_id)

            # White Matter: Look for "white-matter"
            elif "white-matter" in label_name:
                wm_ids.append(label_id)

    print(f"Found GM IDs: {gm_ids}")
    print(f"Found WM IDs: {wm_ids}")
    return gm_ids, wm_ids



class data_preparation(Dataset) : 
    def __init__(self, img_paths, seg_paths, transform=None):
        self.img_paths = img_paths
        self.seg_paths = seg_paths
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)
    
    def __getitem__(self, idx):
        img = self.img_paths[idx]
        seg = self.seg_paths[idx]

        img_np = nib.load(img).get_fdata().squeeze()
        img_np = img_np[:, :160]

        seg_np = nib.load(seg).get_fdata().squeeze()
        seg_np = seg_np[:, :160]

        img = torch.tensor(img_np, dtype=torch.float32)
        seg = torch.tensor(seg_np, dtype=torch.int64)

        sample = {"image": img, "label": seg}
        if self.transform:
            sample = self.transform(sample)
        return sample
    
class UNetModule(pl.LightningModule):
    def __init__(self, learning_rate=1e-3):
        super(UNetModule, self).__init__()
        self.model = UNet(
            spatial_dims=2,
            in_channels=1,
            out_channels=3,
            channels=(16, 32, 64, 128, 256),
            strides=(2, 2, 2, 2),
            num_res_units=2,
        )
        self.loss_function = monai.losses.DiceLoss(to_onehot_y=True, softmax=True)

        self.dice_metric = monai.metrics.DiceMetric(include_background=False, reduction="mean")

        self.post_pred = AsDiscrete(argmax=True)
        self.post_label = AsDiscrete(to_onehot=3)

        self.learning_rate = learning_rate

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch, batch_idx):
        images = batch["image"]
        segs = batch["label"]
        outputs = self(images)
        loss = self.loss_function(outputs, segs)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    
    def validation_step(self, batch, batch_idx):
        images = batch["image"]
        segs = batch["label"]
        outputs = self(images)
        loss = self.loss_function(outputs, segs)


        outputs = self.post_pred(outputs)

        print("DEBUG seg shape:", segs.shape, segs.min().item(), segs.max().item())

        # segs= segs.squeeze(1)

        print("DEBUG seg shape:", segs.shape, segs.min().item(), segs.max().item())

        segs = self.post_label(segs)

        self.dice_metric(outputs, segs)
        self.log("val_loss", loss, prog_bar=True)
        return loss
    
    def on_validation_epoch_end(self):

        dice = self.dice_metric.aggregate().item()
        self.dice_metric.reset()
        self.log("val_dice", dice, prog_bar=True)

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)
        return optimizer



class MergeSegLabels(MapTransform):
    def __init__(self, keys, labels_file_path):
        super().__init__(keys)
        self.labels_path = labels_file_path
        self.gm_ids, self.wm_ids = get_tissue_ids(labels_file_path)

    def __call__(self, data) : 
        d = dict(data)
        for key in self.keys:
            seg = d[key]

            new_seg = np.zeros_like(seg)
            
            new_seg[np.isin(seg, self.gm_ids)] = 1

            new_seg[np.isin(seg, self.wm_ids)] = 2

            d[key] = new_seg
        return d
    

class SqueezeLabel(MapTransform):
    def __call__(self, data):
        d = dict(data)
        for key in self.keys:
            if d[key].ndim == 3 and d[key].shape[0] == 1:  # shape: (1,H,W)
                d[key] = d[key].squeeze(0)
        return d


labels_file_path = "/home/boadem/Work/School/neurite_data/seg24_labels.txt"

seed=42
train_transforms = Compose(
    [

         MergeSegLabels(
            keys=["label"],
            labels_file_path=labels_file_path,
        ),

        EnsureChannelFirstd(
            keys=["image", "label"],
            channel_dim="no_channel"
        ),

        ResizeD(
            keys="image",
            spatial_size=(128, 128),
            mode="area",
        ),
        ResizeD(
            keys="label",
            spatial_size=(128, 128),
            mode="nearest",
        ),

        ScaleIntensityRanged(
            keys="image",
            a_min=0,
            a_max=255,
            b_min=0.0,
            b_max=1.0,
        ),

        RandFlipd(
            keys=["image", "label"],
            prob=0.3,
            spatial_axis=0,
        ),
        RandFlipd(
            keys=["image", "label"],
            prob=0.3,
            spatial_axis=1,
        ),
        RandRotateD(
            keys=["image", "label"],
            range_x=15,
            prob=0.3,
            mode=("bilinear", "nearest"),
        ),

        RandGaussianNoised(
            keys=["image"],
            prob=0.15,
            mean=0.0,
            std=0.01,
        ),

        # ðŸ”‘ REQUIRED
        EnsureTyped(
            keys=["image", "label"],
            dtype=(torch.float32, torch.int64),
        ),
    ],
    lazy=False,
    )
val_transforms = Compose([
    MergeSegLabels(keys=["label"], labels_file_path=labels_file_path),
    EnsureChannelFirstd(keys=["image", "label"], channel_dim="no_channel"),
    ScaleIntensityRanged(keys=["image"], a_min=0, a_max=255, b_min=0.0, b_max=1.0),
    ResizeD(keys=["image"], spatial_size=(128,128), mode="area"),
    ResizeD(keys=["label"], spatial_size=(128,128), mode="nearest"),
    EnsureTyped(keys=["image","label"], dtype=(torch.float32, torch.int64))
])





# train_transforms.set_random_state(seed=42)
# val_transforms.set_random_state(seed=42)


def train(data, transform_train, transform_val, save_dir, log_save_dir, n_epochs = 60, patience = 10) : 

    os.makedirs(save_dir, exist_ok=True)
    os.makedirs(log_save_dir, exist_ok=True)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    
    for fold, (train_idx, val_idx) in enumerate (kf.split(data)) :
        print(f"Starting fold {fold + 1}...")
        
        train_paths = [data[i] for i in train_idx]
        val_paths = [data[i] for i in val_idx]

        train_dataset = data_preparation(
            img_paths=[item["image"] for item in train_paths],
            seg_paths=[item["segmentation"] for item in train_paths],
            transform=transform_train,
        )

        val_dataset = data_preparation(
            img_paths=[item["image"] for item in val_paths],
            seg_paths=[item["segmentation"] for item in val_paths],
            transform=transform_val,
        )


        train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)
        val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)

        model = UNetModule()

        early_stopping = pl.callbacks.EarlyStopping(monitor="val_dice", patience=patience, mode="max")
        logger = pl.loggers.TensorBoardLogger("Unet_brain_mri_logs", name=f"unet_fold_{fold + 1}")

        trainer = pl.Trainer(max_epochs=n_epochs,
                             fast_dev_run=True,
                            callbacks=[early_stopping],
                            logger=logger,
                            accelerator="auto",
                            devices=1)

        trainer.fit(model, train_dataloader, val_dataloader)

        best_model_pat = os.path.join(save_dir, f"best_model_fold_{fold + 1}.pth")
        trainer.save_checkpoint(best_model_pat)
        torch.save(model.state_dict(), best_model_pat)
        print(f"Best model for fold {fold + 1} saved at: {best_model_pat}")

    print("Training complete for all folds.")


train_set = json.load(open("/home/boadem/Work/School/train_set_paths.json"))

# device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")

train(data=train_set, transform_train=train_transforms, transform_val=val_transforms,
      save_dir="/home/boadem/Work/School/Unet_brain_mri_models_WGM",
      log_save_dir="/home/boadem/Work/School/Unet_brain_mri_logs_WGM",
      n_epochs=60,
      patience=10)